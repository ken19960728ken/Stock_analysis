import os

import pandas as pd
import yfinance as yf
from dotenv import load_dotenv
from sqlalchemy import create_engine
from tqdm import tqdm  # é€²åº¦æ¢å·¥å…·

# ==========================================
# 1. åˆå§‹åŒ–èˆ‡è¨­å®š
# ==========================================
# è¼‰å…¥ .env æª”æ¡ˆä¸­çš„å¯†ç¢¼
load_dotenv()

# ç²å–è³‡æ–™åº«é€£ç·šå­—ä¸²
DB_URL = os.getenv("SUPABASE_URL")

if not DB_URL:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° SUPABASE_URLã€‚è«‹æª¢æŸ¥ä½ çš„ .env æª”æ¡ˆã€‚")
    exit()

# å»ºç«‹è³‡æ–™åº«é€£ç·šå¼•æ“
try:
    db_engine = create_engine(DB_URL)
    print(f"get url ={DB_URL}")
    print("âœ… æˆåŠŸé€£ç·šåˆ° Supabase è³‡æ–™åº«")
except Exception as e:
    print(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
    exit()


# ==========================================
# 2. æ ¸å¿ƒé‚è¼¯ï¼šæŠ“å–å…¬é–‹æ•¸æ“š (Yahoo Finance)
# ==========================================
def fetch_and_upload_history(stock_id, period="3y"):
    """
    å¾ Yahoo Finance æŠ“å–æŒ‡å®šè‚¡ç¥¨çš„æ­·å²æ•¸æ“šä¸¦ä¸Šå‚³åˆ° Supabase
    :param stock_id: å°è‚¡ä»£è™Ÿ (e.g., "2330")
    :param period: æŠ“å–æ™‚é–“é•·åº¦ (é è¨­ 3å¹´: "3y")
    """
    ticker = f"{stock_id}.TW"

    try:
        # ä¸‹è¼‰æ•¸æ“š (auto_adjust=False ç¢ºä¿æ‹¿åˆ°åŸå§‹é–‹é«˜ä½æ”¶)
        df = yf.download(ticker, period=period, progress=False, auto_adjust=False)

        if df.empty:
            print(f"âš ï¸ [{stock_id}] æŠ“å–ä¸åˆ°æ•¸æ“š (å¯èƒ½æ˜¯ä¸‹å¸‚æˆ–ä»£è™ŸéŒ¯èª¤)")
            return

        # --- æ•¸æ“šæ¸…æ´— (Data Cleaning) ---
        df = df.reset_index()

        # è™•ç† yfinance å¯èƒ½å‡ºç¾çš„ MultiIndex æ¬„ä½å•é¡Œ
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.droplevel(1)

        # çµ±ä¸€æ¬„ä½åç¨±ç‚ºå°å¯«ï¼Œæ–¹ä¾¿ SQL æŸ¥è©¢
        df.columns = [c.lower() for c in df.columns]

        # è£œä¸Šè‚¡ç¥¨ä»£è™Ÿæ¬„ä½
        df["stock_id"] = stock_id

        # ç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢º
        df["date"] = pd.to_datetime(df["date"]).dt.date

        # åªä¿ç•™æˆ‘å€‘éœ€è¦çš„æ ¸å¿ƒæ¬„ä½
        required_cols = ["date", "stock_id", "open", "high", "low", "close", "volume"]
        # éæ¿¾æ‰ä¸éœ€è¦çš„æ¬„ä½ (å¦‚ Adj Close)
        df = df[[c for c in required_cols if c in df.columns]]

        # --- ä¸Šå‚³æ•¸æ“š (Data Upload) ---
        # ä½¿ç”¨ 'append' æ¨¡å¼ï¼Œå¦‚æœè¡¨ä¸å­˜åœ¨æœƒè‡ªå‹•å»ºç«‹
        # method='multi' åŠ é€Ÿä¸Šå‚³

    except Exception as e:
        # æ•æ‰ä¸¦é¡¯ç¤ºéŒ¯èª¤ï¼Œä½†ä¸ä¸­æ–·æ•´å€‹ç¨‹å¼
        print(f"âŒ [{stock_id}] è™•ç†å¤±æ•—: {e}")

    df.to_sql(
        "daily_price",
        db_engine,
        if_exists="append",
        index=False,
        method="multi",
        chunksize=1000,
    )


# ==========================================
# 3. æŒ‡æ®ä¸­å¿ƒ (Main Execution)
# ==========================================
if __name__ == "__main__":
    # é€™æ˜¯ä½ çš„è§€å¯Ÿæ¸…å–® (Watchlist)
    # ä½ å¯ä»¥åœ¨é€™è£¡åŠ å…¥ä»»ä½•ä½ æƒ³åˆ†æçš„å°è‚¡ä»£è™Ÿ
    target_stocks = [
        "2330",  # å°ç©é›»
        "2317",  # é´»æµ·
        "2454",  # è¯ç™¼ç§‘
        "2603",  # é•·æ¦®
        "0050",  # å…ƒå¤§å°ç£50
    ]

    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œä»»å‹™ï¼šæŠ“å– {len(target_stocks)} æª”è‚¡ç¥¨çš„è¿‘ 3 å¹´æ•¸æ“š...")

    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦æ¢ï¼Œè®“ä½ æ„Ÿè¦ºåƒå€‹å°ˆæ¥­å·¥ç¨‹å¸«
    for stock in tqdm(target_stocks):
        fetch_and_upload_history(stock, period="3y")

    print("\nâœ… ä»»å‹™å®Œæˆã€‚æ•¸æ“šå·²å®‰å…¨å­˜å…¥ä½ çš„ Supabase é›²ç«¯è³‡æ–™åº«ã€‚")
